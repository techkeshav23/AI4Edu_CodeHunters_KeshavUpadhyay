# Student Engagement Recognition System ğŸ“ğŸ‘ï¸
> **ADVITIYA | NxtGen Hackathon 2026 â€” AI for Education**
> *CDAC AI Impact Summit 2026 Â· IIT Ropar Pre-Summit Activity*

[![PyTorch](https://img.shields.io/badge/PyTorch-%23EE4C2C.svg?style=for-the-badge&logo=PyTorch&logoColor=white)](https://pytorch.org/) [![OpenCV](https://img.shields.io/badge/OpenCV-5C3EE8?style=for-the-badge&logo=opencv&logoColor=white)](https://opencv.org/) [![Python](https://img.shields.io/badge/python-3670A0?style=for-the-badge&logo=python&logoColor=ffdd54)](https://www.python.org/)

## ğŸ“– Overview
This project addresses the challenge of measuring student attentiveness in online learning environments. Using Computer Vision and Deep Learning, the system analyses video feeds to classify student engagement levels, providing actionable insights for educators.

**Problem Statement:** Student Engagement Recognition using Visual and rPPG Information.

---

## ğŸ“‚ Submission Structure (Judge-Facing)

```
analyzer/
â”œâ”€â”€ README.md                   # This file
â”œâ”€â”€ requirements.txt            # All dependencies
â”‚
â”œâ”€â”€ task1_2_visual/             # â”€â”€ Visual-based engagement recognition â”€â”€
â”‚   â”œâ”€â”€ train.py                # Self-contained training  (--task 1 | --task 2)
â”‚   â”œâ”€â”€ inference.py            # Self-contained inference (--task 1 | --task 2)
â”‚   â””â”€â”€ model.pth               # Saved after training
â”‚
â”œâ”€â”€ task3_rppg/                 # â”€â”€ rPPG-based engagement recognition â”€â”€
â”‚   â”œâ”€â”€ train.py                # Placeholder / TODO
â”‚   â”œâ”€â”€ inference.py            # Placeholder / TODO
â”‚   â””â”€â”€ model.pth               # Saved after training
â”‚
â””â”€â”€ dataset/
    â”œâ”€â”€ train/                  # Place training videos + labels here
    â””â”€â”€ test/                   # Place test videos + labels here
```

> **Note:** Development files (`src/`, `scripts/`, `data/`, `models/`, `notebooks/`) are also present in the repo for reference but are **not** part of the judge submission.

---

## ğŸ› ï¸ Installation

```bash
git clone <repo_url>
cd analyzer
pip install -r requirements.txt
```

Requires **Python 3.8+** and a CUDA-capable GPU (recommended).

---

## âš¡ Quick Start â€” Task 1 & 2 (Visual)

### Training

```bash
# Task 1 â€” Binary (Engaged / Not-Engaged)
python task1_2_visual/train.py \
    --task 1 \
    --data_dir dataset/train \
    --labels  dataset/train/labels.xlsx \
    --epochs 50

# Task 2 â€” 4-class (Highly / Nominally / Disengaged / Distracted)
python task1_2_visual/train.py \
    --task 2 \
    --data_dir dataset/train \
    --labels  dataset/train/labels.xlsx \
    --epochs 50
```

The best model is saved to `task1_2_visual/model.pth`.

### Inference / Evaluation

```bash
# Task 1
python task1_2_visual/inference.py \
    --task 1 \
    --data_dir dataset/test \
    --labels  dataset/test/labels.xlsx \
    --model   task1_2_visual/model.pth

# Task 2
python task1_2_visual/inference.py \
    --task 2 \
    --data_dir dataset/test \
    --labels  dataset/test/labels.xlsx \
    --model   task1_2_visual/model.pth
```

**Reported Metrics:**
| Task | Metrics |
|------|---------|
| Task 1 (Binary) | Accuracy, F1-score, Confusion Matrix |
| Task 2 (4-class) | Accuracy, F1-macro, per-class accuracy, Confusion Matrix |

---

## âš¡ Quick Start â€” Task 3 (rPPG)

> *Placeholder â€” implementation in progress.*

```bash
python task3_rppg/train.py     --data_dir dataset/train ...
python task3_rppg/inference.py --data_dir dataset/test  ...
```

---

## ğŸ§  Methodology

### Visual Pipeline (Task 1 & 2)

1. **Face Extraction:** MediaPipe detects and crops faces at **6 FPS** (research-standard temporal resolution).
2. **Model:** **ResNet18** (ImageNet-pretrained) with selective fine-tuning (layer3 + layer4 + FC unfrozen).
3. **Regularisation:**
   - MixUp augmentation (Î± = 0.2 binary / 0.1 multi-class)
   - Dropout (0.5), Label Smoothing (0.15 / 0.1)
   - Class-weighted CrossEntropyLoss
4. **Optimiser:** AdamW with differential LR (backbone 5e-5 / head 5e-4) + CosineAnnealingLR.
5. **Inference:** Test-Time Augmentation (horizontal flip) + probability averaging across all frames per video.

### rPPG Pipeline (Task 3)

*Planned: CHROM / POS / DeepPhys via rPPG-Toolbox integration.*

---

## ğŸ“ Development Files (in `backup/`)

All original development files have been moved to `backup/` to keep the submission clean:

```
backup/
  â”œâ”€â”€ scripts/                 # Dev training & evaluation scripts
  â”œâ”€â”€ src/                     # Modular source code (config, models, dataset)
  â”œâ”€â”€ data/                    # Raw videos & processed frames
  â”œâ”€â”€ models/                  # Dev model checkpoints (.pth)
  â”œâ”€â”€ notebooks/               # Exploration notebooks
  â”œâ”€â”€ results_task1.csv        # Previous evaluation results
  â”œâ”€â”€ results_validation.csv
  â”œâ”€â”€ validation_split.txt
  â”œâ”€â”€ Project_Status_Report.md
  â”œâ”€â”€ PS.md, Rules.md, Rules_Clarification.md
  â””â”€â”€ 1.avi, 2.avi             # Sample test videos
```

---

## ğŸ¤ Team
**Team Analyzer**
*   *Participating in IIT Ropar Advitiya Hackathon 2026*
*   **Track:** AI for Education

---

## ğŸ“œ License
This project is created for the *ADVITIYA | NxtGen Hackathon 2026 â€” CDAC AI Impact Summit*.
